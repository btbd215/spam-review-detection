{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local import\n",
    "import sys\n",
    "if \"../../\" not in sys.path:\n",
    "    sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for preprocessing\n",
    "from src.preprocessing import BasicTextCleaning\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, VarianceThreshold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# for modelling\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of OFS:  (40432, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "0                Home_and_Kitchen_5     5.0    CG   \n",
       "1                Home_and_Kitchen_5     5.0    CG   \n",
       "2                Home_and_Kitchen_5     5.0    CG   \n",
       "3                Home_and_Kitchen_5     1.0    CG   \n",
       "4                Home_and_Kitchen_5     5.0    CG   \n",
       "...                             ...     ...   ...   \n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  \n",
       "0      Love this!  Well made, sturdy, and very comfor...  \n",
       "1      love it, a great upgrade from the original.  I...  \n",
       "2      This pillow saved my back. I love the look and...  \n",
       "3      Missing information on how to use it, but it i...  \n",
       "4      Very nice set. Good quality. We have had the s...  \n",
       "...                                                  ...  \n",
       "40427  I had read some reviews saying that this bra r...  \n",
       "40428  I wasn't sure exactly what it would be. It is ...  \n",
       "40429  You can wear the hood by itself, wear it with ...  \n",
       "40430  I liked nothing about this dress. The only rea...  \n",
       "40431  I work in the wedding industry and have to wor...  \n",
       "\n",
       "[40432 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osf = pd.read_csv(\"../../data/fake_reviews_dataset.csv\")\n",
    "print(\"Shape of OFS: \", osf.shape)\n",
    "# osf.head()\n",
    "osf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = BasicTextCleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    osf_cleaned = pd.read_csv(\"../../data/cleaned/osf_cleaned.csv\")\n",
    "    osf_cleaned = osf_cleaned.replace(np.nan, '')\n",
    "except:\n",
    "    osf_cleaned = pd.DataFrame()\n",
    "    osf_cleaned['length'] = osf['text_'].apply(lambda x: len(x))\n",
    "    osf_cleaned['texts'] = cleaner.text_cleaning(osf['text_'])\n",
    "\n",
    "    ordinal = OrdinalEncoder(categories=[['OR', 'CG']], dtype=int)\n",
    "    osf_cleaned['labels'] = ordinal.fit_transform(osf[['label']])\n",
    "    osf_cleaned.to_csv(\"../../data/cleaned/osf_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(sentences, w2v_model):\n",
    "    avg_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence:\n",
    "            avg_sentence = np.mean([w2v_model.wv.get_vector(word) for word in sentence if word in w2v_model.wv.key_to_index], axis=0)\n",
    "        else:\n",
    "            avg_sentence = np.zeros(w2v_model.vector_size)\n",
    "        avg_sentences.append(avg_sentence)\n",
    "    return np.array(avg_sentences)\n",
    "\n",
    "def text_extractor(X_train, X_test, extractor):\n",
    "    if isinstance(extractor, Word2Vec):\n",
    "        vector_size = extractor.vector_size\n",
    "        window = extractor.window\n",
    "        sg = extractor.sg\n",
    "        extractor = Word2Vec(vector_size=vector_size, sg=sg, window=window, min_count=1, workers=5, seed=42)\n",
    "\n",
    "        cleaner = BasicTextCleaning()\n",
    "        X_train = cleaner.text_cleaning(texts=X_train, methods=['tokenization'])\n",
    "        X_test = cleaner.text_cleaning(texts=X_test, methods=['tokenization'])\n",
    "\n",
    "        extractor.build_vocab(X_train)\n",
    "        extractor.train(X_train, total_examples=extractor.corpus_count, epochs=30)\n",
    "        X_train = avg_word2vec(X_train, extractor)\n",
    "        X_train = pd.DataFrame(X_train, columns=[str(i) for i in range(extractor.vector_size)])\n",
    "        X_test = avg_word2vec(X_test, extractor)\n",
    "        X_test = pd.DataFrame(X_test, columns=[str(i) for i in range(extractor.vector_size)])\n",
    "    else:\n",
    "        X_train = extractor.fit_transform(X_train).toarray()\n",
    "        X_test = extractor.transform(X_test).toarray()\n",
    "        X_train = pd.DataFrame(X_train, columns=extractor.get_feature_names_out())\n",
    "        X_test = pd.DataFrame(X_test, columns=extractor.get_feature_names_out())\n",
    "    \n",
    "    variance = VarianceThreshold()\n",
    "    X_train = variance.fit_transform(X_train)\n",
    "    X_test = variance.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=variance.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=variance.get_feature_names_out())\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def feature_selection(X_train, X_test, selector):\n",
    "    X_train = selector.fit_transform(X_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=selector.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=selector.get_feature_names_out())\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(model, X_train, y_train, X_test, probability=True):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if probability:\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        return y_pred, y_pred_proba\n",
    "    return y_pred\n",
    "\n",
    "def evaluation(y_true, y_pred, y_pred_prob, scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc']):\n",
    "    scores = {'accuracy': accuracy_score,\n",
    "              'f1': f1_score,\n",
    "              'recall': recall_score,\n",
    "              'precision': precision_score,\n",
    "              'roc_auc': roc_auc_score}\n",
    "    \n",
    "    result = {}\n",
    "    for method in scoring:\n",
    "        if method == 'roc_auc':\n",
    "            result[method] = scores[method](y_true, y_pred_prob.T[1])\n",
    "        else:\n",
    "            result[method] = scores[method](y_true, y_pred)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, extractor, model=None, selector=None, length_scaler=None,\n",
    "                     scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], cv=5,\n",
    "                     avg_output=True, quiet=True):\n",
    "    kfolds = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = {method: [] for method in scoring}\n",
    "    round = 1\n",
    "\n",
    "    for train_indices, test_indices in kfolds.split(data.iloc[:, :-1], data.iloc[:, -1]):\n",
    "        train_set, test_set = data.iloc[train_indices, :-1], data.iloc[test_indices, :-1]\n",
    "        y_train, y_test = data.iloc[train_indices, -1], data.iloc[test_indices, -1]\n",
    "\n",
    "        X_train, X_test = text_extractor(X_train=train_set['texts'], X_test=test_set['texts'], extractor=extractor)\n",
    "\n",
    "        if length_scaler is not None:\n",
    "            X_train['length'] = length_scaler.fit_transform(train_set[['length']])\n",
    "            X_test['length'] = length_scaler.transform(test_set[['length']])\n",
    "        \n",
    "        if selector is not None:\n",
    "            X_train, X_test = feature_selection(X_train, X_test, selector)\n",
    "\n",
    "        y_pred, y_pred_prob = modelling(model, X_train, y_train, X_test)\n",
    "\n",
    "        result = evaluation(y_true=y_test, y_pred=y_pred, y_pred_prob=y_pred_prob, scoring=scoring)\n",
    "        for method in scoring:\n",
    "            scores[method].append(result[method])\n",
    "            \n",
    "        if not quiet:\n",
    "            print(f\"round {round}: done\")\n",
    "\n",
    "        round += 1\n",
    "        \n",
    "    if avg_output:\n",
    "        avg_scores = {key: np.mean(values) for key, values in scores.items()}\n",
    "\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1: done\n",
      "round 2: done\n",
      "round 3: done\n",
      "round 4: done\n",
      "round 5: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8606548082210462,\n",
       " 'f1': 0.8603401641065223,\n",
       " 'recall': 0.8586468095233762,\n",
       " 'precision': 0.862047397940788,\n",
       " 'roc_auc': 0.9367511305235844}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = Word2Vec(window=5,\n",
    "                     vector_size=50,\n",
    "                     seed=42,\n",
    "                     sg=1)\n",
    "model = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "# model = SVC(probability=True, class_weight='balanced')\n",
    "extractor = TfidfVectorizer(min_df=0.001, ngram_range=(1, 1))\n",
    "# model = SVC()\n",
    "\n",
    "cross_validation(data=osf_cleaned, length_scaler=StandardScaler(),\n",
    "                 model=model, extractor=extractor, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcases = {'data': {'osf': osf_cleaned},\n",
    "             'length_used': {'None': None,\n",
    "                             'StandardScaler': StandardScaler(),\n",
    "                             'MinMaxScaler': MinMaxScaler()},\n",
    "             'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "             'feature selection': {'None': None,\n",
    "                                   'PCA': PCA,\n",
    "                                   'SelectKBest(score_func={}, k={})': SelectKBest},\n",
    "             'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'data': [],\n",
    "          'length_used': [],\n",
    "          'feature_extraction': [],\n",
    "          'feature_selection': [],\n",
    "          'model': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': [],\n",
    "          'notes': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = {'data': [],\n",
    "#           'length_used': [],\n",
    "#           'feature_extraction': [],\n",
    "#           'feature_selection': [],\n",
    "#           'model': [],\n",
    "#           'accuracy': [],\n",
    "#           'f1': [],\n",
    "#           'recall': [],\n",
    "#           'precision': [],\n",
    "#           'roc_auc': [],\n",
    "#           'notes': []}\n",
    "\n",
    "# testcases = {'data': {'osf': osf_cleaned},\n",
    "#              'length_used': {'None': None,\n",
    "#                              'StandardScaler': StandardScaler(),\n",
    "#                              'MinMaxScaler': MinMaxScaler()},\n",
    "#              'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "#              'feature selection': {'None': None},\n",
    "#              'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}\n",
    "\n",
    "# for data_name in testcases['data']:\n",
    "#     for length in testcases['length_used']:\n",
    "#         if length == 'None':\n",
    "#             data = testcases['data'][data_name].iloc[:, 1:].copy()\n",
    "#         else:\n",
    "#             data = testcases['data'][data_name].copy()\n",
    "#         for size in np.arange(100, 1100, 100):\n",
    "#             for window in range(3, 9, 2):\n",
    "#                 extractor = Word2Vec(vector_size=size, window=window, workers=5, min_count=1, seed=42)\n",
    "#                 for selector_name in testcases['feature selection']:\n",
    "#                     selector = testcases['feature selection'][selector_name]\n",
    "#                     for model_name in testcases['model']:\n",
    "#                         model = testcases['model'][model_name]\n",
    "#                         scores = cross_validation(data=data,\n",
    "#                                                   length_scaler=testcases['length_used'][length],\n",
    "#                                                   extractor=extractor,\n",
    "#                                                   selector=selector,\n",
    "#                                                   model=model)\n",
    "                        \n",
    "#                         output['data'].append(data_name)\n",
    "#                         output['length_used'].append(length)\n",
    "#                         output['feature_extraction'].append(f'Word2Vec(vector_size={size}, window={window})')\n",
    "#                         output['feature_selection'].append(selector_name)\n",
    "#                         output['model'].append(model_name)\n",
    "#                         for key, values in scores.items():\n",
    "#                             output[key].append(values)\n",
    "\n",
    "output = {'data': [],\n",
    "          'length_used': [],\n",
    "          'feature_extraction': [],\n",
    "          'feature_selection': [],\n",
    "          'model': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': [],\n",
    "          'notes': []}\n",
    "\n",
    "testcases = {'data': {'osf': osf_cleaned},\n",
    "             'length_used': {'None': None},\n",
    "             'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "             'feature selection': {'None': None},\n",
    "             'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}\n",
    "\n",
    "for data_name in testcases['data']:\n",
    "    for length in testcases['length_used']:\n",
    "        if length == 'None':\n",
    "            data = testcases['data'][data_name].iloc[:, 1:].copy()\n",
    "        else:\n",
    "            data = testcases['data'][data_name].copy()\n",
    "        for size in np.arange(300, 310, 100):\n",
    "            for window in range(3, 9, 2):\n",
    "                extractor = Word2Vec(vector_size=size, window=window, workers=5, min_count=1, seed=42, sg=1)\n",
    "                for selector_name in testcases['feature selection']:\n",
    "                    selector = testcases['feature selection'][selector_name]\n",
    "                    for model_name in testcases['model']:\n",
    "                        model = testcases['model'][model_name]\n",
    "                        scores = cross_validation(data=data,\n",
    "                                                  length_scaler=testcases['length_used'][length],\n",
    "                                                  extractor=extractor,\n",
    "                                                  selector=selector,\n",
    "                                                  model=model)\n",
    "                        \n",
    "                        output['data'].append(data_name)\n",
    "                        output['length_used'].append(length)\n",
    "                        output['feature_extraction'].append(f'Word2Vec(vector_size={size}, window={window}, sg=1)')\n",
    "                        output['feature_selection'].append(selector_name)\n",
    "                        output['model'].append(model_name)\n",
    "                        for key, values in scores.items():\n",
    "                            output[key].append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved = output.copy()\n",
    "output_saved['notes'] = ['']*len(output_saved['data'])\n",
    "# # # pd.DataFrame(output_saved).to_csv(\"data/result/test_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=3, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852790</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.847592</td>\n",
       "      <td>0.916757</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=5, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856104</td>\n",
       "      <td>0.856744</td>\n",
       "      <td>0.860741</td>\n",
       "      <td>0.852789</td>\n",
       "      <td>0.918914</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=7, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856995</td>\n",
       "      <td>0.857416</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>0.854797</td>\n",
       "      <td>0.918974</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data length_used                         feature_extraction  \\\n",
       "0  osf        None  Word2Vec(vector_size=300, window=3, sg=1)   \n",
       "1  osf        None  Word2Vec(vector_size=300, window=5, sg=1)   \n",
       "2  osf        None  Word2Vec(vector_size=300, window=7, sg=1)   \n",
       "\n",
       "  feature_selection                                              model  \\\n",
       "0              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "1              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "2              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "\n",
       "   accuracy        f1    recall  precision   roc_auc notes  \n",
       "0  0.852790  0.853824  0.860172   0.847592  0.916757        \n",
       "1  0.856104  0.856744  0.860741   0.852789  0.918914        \n",
       "2  0.856995  0.857416  0.860076   0.854797  0.918974        "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_saved_df = pd.DataFrame(output_saved)\n",
    "output_saved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.842649</td>\n",
       "      <td>0.843850</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.855068</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.849649</td>\n",
       "      <td>0.850687</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.846878</td>\n",
       "      <td>0.915526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.854348</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.861271</td>\n",
       "      <td>0.849461</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852394</td>\n",
       "      <td>0.852961</td>\n",
       "      <td>0.856477</td>\n",
       "      <td>0.849482</td>\n",
       "      <td>0.916127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=7, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852493</td>\n",
       "      <td>0.852787</td>\n",
       "      <td>0.854665</td>\n",
       "      <td>0.850929</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=3, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852790</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.847592</td>\n",
       "      <td>0.916757</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=5, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856104</td>\n",
       "      <td>0.856744</td>\n",
       "      <td>0.860741</td>\n",
       "      <td>0.852789</td>\n",
       "      <td>0.918914</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=300, window=7, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856995</td>\n",
       "      <td>0.857416</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>0.854797</td>\n",
       "      <td>0.918974</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data length_used                         feature_extraction  \\\n",
       "0   osf         NaN        Word2Vec(vector_size=100, window=3)   \n",
       "1   osf         NaN        Word2Vec(vector_size=100, window=5)   \n",
       "2   osf         NaN        Word2Vec(vector_size=100, window=7)   \n",
       "3   osf         NaN        Word2Vec(vector_size=200, window=3)   \n",
       "4   osf         NaN        Word2Vec(vector_size=200, window=5)   \n",
       "..  ...         ...                                        ...   \n",
       "94  osf         NaN  Word2Vec(vector_size=200, window=5, sg=1)   \n",
       "95  osf         NaN  Word2Vec(vector_size=200, window=7, sg=1)   \n",
       "96  osf        None  Word2Vec(vector_size=300, window=3, sg=1)   \n",
       "97  osf        None  Word2Vec(vector_size=300, window=5, sg=1)   \n",
       "98  osf        None  Word2Vec(vector_size=300, window=7, sg=1)   \n",
       "\n",
       "   feature_selection                                              model  \\\n",
       "0                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "1                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "2                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "3                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "4                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "..               ...                                                ...   \n",
       "94               NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "95               NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "96              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "97              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "98              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "\n",
       "    accuracy        f1    recall  precision   roc_auc notes  \n",
       "0   0.842649  0.843850  0.850587   0.837234  0.906563   NaN  \n",
       "1   0.847769  0.848826  0.855068   0.842681  0.911585   NaN  \n",
       "2   0.849649  0.850687  0.856728   0.844732  0.913208   NaN  \n",
       "3   0.852518  0.853635  0.860505   0.846878  0.915526   NaN  \n",
       "4   0.854348  0.855324  0.861271   0.849461  0.917639   NaN  \n",
       "..       ...       ...       ...        ...       ...   ...  \n",
       "94  0.852394  0.852961  0.856477   0.849482  0.916127   NaN  \n",
       "95  0.852493  0.852787  0.854665   0.850929  0.916700   NaN  \n",
       "96  0.852790  0.853824  0.860172   0.847592  0.916757        \n",
       "97  0.856104  0.856744  0.860741   0.852789  0.918914        \n",
       "98  0.856995  0.857416  0.860076   0.854797  0.918974        \n",
       "\n",
       "[99 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = pd.read_csv('data/result/test_result.csv')\n",
    "# result = pd.concat([result, output_saved_df], axis=0, ignore_index=True)\n",
    "# # result.sort_values(by='accuracy', ascending=True)\n",
    "# # result[result['feature_extraction']=='Word2Vec(vector_size=100, window=5)']\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('data/result/test_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.842649</td>\n",
       "      <td>0.843850</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.855068</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.849649</td>\n",
       "      <td>0.850687</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.846878</td>\n",
       "      <td>0.915526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.854348</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.861271</td>\n",
       "      <td>0.849461</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852394</td>\n",
       "      <td>0.852961</td>\n",
       "      <td>0.856477</td>\n",
       "      <td>0.849482</td>\n",
       "      <td>0.916127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=7, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852493</td>\n",
       "      <td>0.852787</td>\n",
       "      <td>0.854665</td>\n",
       "      <td>0.850929</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=3, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852790</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.847592</td>\n",
       "      <td>0.916757</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=5, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856104</td>\n",
       "      <td>0.856744</td>\n",
       "      <td>0.860741</td>\n",
       "      <td>0.852789</td>\n",
       "      <td>0.918914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=7, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856995</td>\n",
       "      <td>0.857416</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>0.854797</td>\n",
       "      <td>0.918974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data length_used                         feature_extraction  \\\n",
       "0   osf         NaN        Word2Vec(vector_size=100, window=3)   \n",
       "1   osf         NaN        Word2Vec(vector_size=100, window=5)   \n",
       "2   osf         NaN        Word2Vec(vector_size=100, window=7)   \n",
       "3   osf         NaN        Word2Vec(vector_size=200, window=3)   \n",
       "4   osf         NaN        Word2Vec(vector_size=200, window=5)   \n",
       "..  ...         ...                                        ...   \n",
       "94  osf         NaN  Word2Vec(vector_size=200, window=5, sg=1)   \n",
       "95  osf         NaN  Word2Vec(vector_size=200, window=7, sg=1)   \n",
       "96  osf         NaN  Word2Vec(vector_size=300, window=3, sg=1)   \n",
       "97  osf         NaN  Word2Vec(vector_size=300, window=5, sg=1)   \n",
       "98  osf         NaN  Word2Vec(vector_size=300, window=7, sg=1)   \n",
       "\n",
       "    feature_selection                                              model  \\\n",
       "0                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "1                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "2                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "3                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "4                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "..                ...                                                ...   \n",
       "94                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "95                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "96                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "97                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "98                NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "\n",
       "    accuracy        f1    recall  precision   roc_auc  notes  \n",
       "0   0.842649  0.843850  0.850587   0.837234  0.906563    NaN  \n",
       "1   0.847769  0.848826  0.855068   0.842681  0.911585    NaN  \n",
       "2   0.849649  0.850687  0.856728   0.844732  0.913208    NaN  \n",
       "3   0.852518  0.853635  0.860505   0.846878  0.915526    NaN  \n",
       "4   0.854348  0.855324  0.861271   0.849461  0.917639    NaN  \n",
       "..       ...       ...       ...        ...       ...    ...  \n",
       "94  0.852394  0.852961  0.856477   0.849482  0.916127    NaN  \n",
       "95  0.852493  0.852787  0.854665   0.850929  0.916700    NaN  \n",
       "96  0.852790  0.853824  0.860172   0.847592  0.916757    NaN  \n",
       "97  0.856104  0.856744  0.860741   0.852789  0.918914    NaN  \n",
       "98  0.856995  0.857416  0.860076   0.854797  0.918974    NaN  \n",
       "\n",
       "[99 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(r\"../../output/csv/test_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
